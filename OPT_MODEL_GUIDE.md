# OPT æ¨¡å‹ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•åœ¨ Wanda ä¸­ä½¿ç”¨ Facebook çš„ OPT (Open Pre-trained Transformer) æ¨¡å‹ã€‚

---

## ğŸ¯ å¿«é€Ÿå›ç­”

**Q: Wanda ä½¿ç”¨ OPT æ¨¡å‹éœ€è¦ç‰¹æ®Šçš„ HF æ ¼å¼å—ï¼Ÿ**

**A: ä¸éœ€è¦ï¼** Facebook åœ¨ Hugging Face ä¸Šå‘å¸ƒçš„ OPT æ¨¡å‹å·²ç»æ˜¯æ ‡å‡†çš„ Hugging Face æ ¼å¼ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚

---

## ğŸ“¦ å¯ç”¨çš„ OPT æ¨¡å‹

æ‰€æœ‰ OPT æ¨¡å‹éƒ½å¯ä»¥ç›´æ¥ä» Hugging Face ä¸‹è½½å’Œä½¿ç”¨ï¼š

| æ¨¡å‹ ID | å‚æ•°é‡ | è¯´æ˜ |
|---------|--------|------|
| `facebook/opt-125m` | 125M | æœ€å°æ¨¡å‹ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯• |
| `facebook/opt-350m` | 350M | å°å‹æ¨¡å‹ |
| `facebook/opt-1.3b` | 1.3B | ä¸­å°å‹æ¨¡å‹ |
| `facebook/opt-2.7b` | 2.7B | ä¸­å‹æ¨¡å‹ |
| `facebook/opt-6.7b` | 6.7B | å¤§å‹æ¨¡å‹ |
| `facebook/opt-13b` | 13B | è¶…å¤§å‹æ¨¡å‹ |
| `facebook/opt-30b` | 30B | è¶…å¤§å‹æ¨¡å‹ï¼ˆéœ€è¦å¤š GPUï¼‰ |
| `facebook/opt-66b` | 66B | æœ€å¤§æ¨¡å‹ï¼ˆéœ€è¦å¤š GPUï¼‰ |

**å®˜æ–¹é“¾æ¥**: https://huggingface.co/facebook

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1ï¸âƒ£ åŸºæœ¬ç”¨æ³•

```bash
python main_opt.py \
    --model facebook/opt-6.7b \
    --prune_method wanda \
    --sparsity_ratio 0.5 \
    --sparsity_type unstructured \
    --save out/opt_6.7b/unstructured/wanda/
```

### 2ï¸âƒ£ ç»“æ„åŒ–ç¨€ç–ï¼ˆ2:4ï¼‰

```bash
python main_opt.py \
    --model facebook/opt-6.7b \
    --prune_method wanda \
    --sparsity_ratio 0.5 \
    --sparsity_type 2:4 \
    --save out/opt_6.7b/2-4/wanda/
```

### 3ï¸âƒ£ ä½¿ç”¨æœ¬åœ°ç¼“å­˜

```bash
python main_opt.py \
    --model facebook/opt-6.7b \
    --prune_method wanda \
    --sparsity_ratio 0.5 \
    --sparsity_type unstructured \
    --cache_dir /path/to/llm_weights \
    --save out/opt_6.7b/unstructured/wanda/
```

---

## âš™ï¸ OPT vs LLaMA çš„åŒºåˆ«

### å…³é”®å·®å¼‚

| ç‰¹æ€§ | LLaMA | OPT |
|------|-------|-----|
| **è„šæœ¬** | `main.py` | `main_opt.py` |
| **å‰ªæåº“** | `lib/prune.py` | `lib/prune_opt.py` |
| **å±‚è·¯å¾„** | `model.layers` | `model.decoder.layers` |
| **æ¶æ„** | Decoder-only | Decoder-only |
| **ä½ç½®ç¼–ç ** | RoPE | Learned |

### ä¸ºä»€ä¹ˆéœ€è¦ä¸åŒçš„è„šæœ¬ï¼Ÿ

OPT å’Œ LLaMA çš„æ¨¡å‹ç»“æ„ç•¥æœ‰ä¸åŒï¼Œä¸»è¦ä½“ç°åœ¨ï¼š

1. **å±‚è®¿é—®è·¯å¾„**ï¼š
   ```python
   # LLaMA
   layers = model.model.layers
   
   # OPT
   layers = model.model.decoder.layers
   ```

2. **æ³¨æ„åŠ›æœºåˆ¶**ï¼š
   - LLaMA ä½¿ç”¨ RoPE (Rotary Position Embedding)
   - OPT ä½¿ç”¨ä¼ ç»Ÿçš„ Learned Position Embedding

3. **å½’ä¸€åŒ–å±‚**ï¼š
   - LLaMA ä½¿ç”¨ RMSNorm
   - OPT ä½¿ç”¨ LayerNorm

---

## ğŸ§ª æµ‹è¯• OPT æ¨¡å‹

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªæµ‹è¯•è„šæœ¬æ¥éªŒè¯ OPT æ¨¡å‹çš„å…¼å®¹æ€§ï¼š

```bash
# æµ‹è¯•æœ€å°çš„ OPT æ¨¡å‹
python test_opt_model.py

# æµ‹è¯•ç‰¹å®šçš„ OPT æ¨¡å‹
python test_opt_model.py facebook/opt-1.3b
```

**æµ‹è¯•å†…å®¹**ï¼š
- âœ… æ¨¡å‹åŠ è½½
- âœ… Tokenizer åŠ è½½
- âœ… æ¨¡å‹ç»“æ„æ£€æŸ¥
- âœ… æ¨ç†æµ‹è¯•
- âœ… æ ¼å¼éªŒè¯

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

### OPT æ¨¡å‹åœ¨ WikiText2 ä¸Šçš„ PPLï¼ˆ50% ç¨€ç–åº¦ï¼‰

| æ¨¡å‹ | Dense PPL | Magnitude | Wanda | SparseGPT |
|------|-----------|-----------|-------|-----------|
| OPT-125M | ~27.65 | ~45.0 | ~30.5 | ~29.8 |
| OPT-1.3B | ~14.62 | ~22.0 | ~16.5 | ~16.0 |
| OPT-6.7B | ~10.86 | ~15.5 | ~12.2 | ~11.8 |
| OPT-13B | ~10.13 | ~14.0 | ~11.5 | ~11.0 |

*æ³¨ï¼šä»¥ä¸Šæ•°æ®ä¸ºä¼°è®¡å€¼ï¼Œå®é™…ç»“æœå¯èƒ½å› é…ç½®è€Œå¼‚*

---

## ğŸ” æ¨¡å‹æ ¼å¼è¯´æ˜

### Hugging Face åŸç”Ÿæ ¼å¼

Facebook å‘å¸ƒçš„ OPT æ¨¡å‹å·²ç»æ˜¯ Hugging Face çš„æ ‡å‡†æ ¼å¼ï¼š

```
facebook/opt-6.7b/
â”œâ”€â”€ config.json              # æ¨¡å‹é…ç½®
â”œâ”€â”€ pytorch_model.bin        # æ¨¡å‹æƒé‡ï¼ˆæ—§æ ¼å¼ï¼‰
â”œâ”€â”€ model.safetensors        # æ¨¡å‹æƒé‡ï¼ˆæ–°æ ¼å¼ï¼Œæ¨èï¼‰
â”œâ”€â”€ tokenizer.json           # Tokenizer é…ç½®
â”œâ”€â”€ tokenizer_config.json    # Tokenizer å…ƒæ•°æ®
â””â”€â”€ special_tokens_map.json  # ç‰¹æ®Š token æ˜ å°„
```

### æ— éœ€è½¬æ¢

- âœ… **ä¸éœ€è¦**ä» Fairseq æ ¼å¼è½¬æ¢
- âœ… **ä¸éœ€è¦**ä» Megatron æ ¼å¼è½¬æ¢
- âœ… **ä¸éœ€è¦**ä»»ä½•é¢„å¤„ç†
- âœ… ç›´æ¥ä½¿ç”¨ `AutoModelForCausalLM.from_pretrained()`

---

## ğŸ’¡ å¸¸è§é—®é¢˜

### Q1: OPT æ¨¡å‹éœ€è¦ç‰¹æ®Šçš„ HF æ ¼å¼å—ï¼Ÿ

**A**: ä¸éœ€è¦ã€‚Facebook åœ¨ Hugging Face ä¸Šå‘å¸ƒçš„ OPT æ¨¡å‹å·²ç»æ˜¯æ ‡å‡†æ ¼å¼ã€‚

### Q2: å¯ä»¥ç”¨ `main.py` å‰ªæ OPT å—ï¼Ÿ

**A**: ä¸æ¨èã€‚è™½ç„¶ç†è®ºä¸Šå¯èƒ½å·¥ä½œï¼Œä½† `main_opt.py` ä¸“é—¨ä¸º OPT çš„å±‚ç»“æ„ä¼˜åŒ–ï¼Œä½¿ç”¨å®ƒæ›´å®‰å…¨ã€‚

### Q3: OPT å’Œ LLaMA å“ªä¸ªæ›´å¥½ï¼Ÿ

**A**: 
- **OPT**: æ›´æ—©å‘å¸ƒï¼Œç¤¾åŒºæ”¯æŒå¹¿æ³›ï¼Œé€‚åˆç ”ç©¶
- **LLaMA**: æ€§èƒ½æ›´å¥½ï¼Œæ›´æ–°çš„æ¶æ„ï¼Œæ¨èç”¨äºç”Ÿäº§

### Q4: å¯ä»¥åœ¨ OPT ä¸Šä½¿ç”¨æ··åˆä¸‰å±‚å‰ªæå—ï¼Ÿ

**A**: ç†è®ºä¸Šå¯ä»¥ï¼Œä½†éœ€è¦ä¿®æ”¹ `main_block_three_tier.py` ä¸­çš„å±‚è®¿é—®è·¯å¾„ï¼š

```python
# ä¿®æ”¹å‰ï¼ˆLLaMAï¼‰
layers = model.model.layers

# ä¿®æ”¹åï¼ˆOPTï¼‰
layers = model.model.decoder.layers
```

### Q5: OPT æ¨¡å‹æ”¯æŒå“ªäº›è¯­è¨€ï¼Ÿ

**A**: OPT ä¸»è¦æ˜¯è‹±æ–‡æ¨¡å‹ï¼Œåœ¨å…¶ä»–è¯­è¨€ä¸Šçš„è¡¨ç°å¯èƒ½ä¸å¦‚ä¸“é—¨çš„å¤šè¯­è¨€æ¨¡å‹ã€‚

---

## ğŸ”§ é«˜çº§ç”¨æ³•

### 1. å¤š GPU å‰ªæï¼ˆ30B/66B æ¨¡å‹ï¼‰

```bash
python main_opt.py \
    --model facebook/opt-30b \
    --prune_method wanda \
    --sparsity_ratio 0.5 \
    --sparsity_type unstructured \
    --save out/opt_30b/unstructured/wanda/
```

ä»£ç ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨å¤š GPUï¼š

```python
if "30b" in args.model or "66b" in args.model:
    device = model.hf_device_map["lm_head"]
```

### 2. Zero-Shot è¯„ä¼°

```bash
python main_opt.py \
    --model facebook/opt-6.7b \
    --prune_method wanda \
    --sparsity_ratio 0.5 \
    --sparsity_type unstructured \
    --save out/opt_6.7b/unstructured/wanda/ \
    --eval_zero_shot
```

### 3. ä¿å­˜å‰ªæåçš„æ¨¡å‹

```bash
python main_opt.py \
    --model facebook/opt-6.7b \
    --prune_method wanda \
    --sparsity_ratio 0.5 \
    --sparsity_type unstructured \
    --save out/opt_6.7b/unstructured/wanda/ \
    --save_model out/opt_6.7b/unstructured/wanda/pruned_model
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### å®˜æ–¹èµ„æº

- [OPT è®ºæ–‡](https://arxiv.org/abs/2205.01068)
- [OPT GitHub](https://github.com/facebookresearch/metaseq)
- [Hugging Face OPT æ¨¡å‹](https://huggingface.co/facebook)

### Wanda ç›¸å…³

- [Wanda è®ºæ–‡](https://arxiv.org/abs/2306.11695)
- [Wanda GitHub](https://github.com/locuslab/wanda)

---

## ğŸ› ï¸ æ•…éšœæ’é™¤

### é—®é¢˜ 1: æ¨¡å‹ä¸‹è½½å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# ä½¿ç”¨é•œåƒç«™ç‚¹
export HF_ENDPOINT=https://hf-mirror.com
python main_opt.py --model facebook/opt-6.7b ...
```

### é—®é¢˜ 2: å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹æµ‹è¯•
python main_opt.py --model facebook/opt-125m ...

# æˆ–ä½¿ç”¨ CPU offload
python main_opt.py --model facebook/opt-6.7b ... --device_map auto
```

### é—®é¢˜ 3: å±‚è·¯å¾„é”™è¯¯

**ç—‡çŠ¶**: `AttributeError: 'OPTModel' object has no attribute 'layers'`

**è§£å†³æ–¹æ¡ˆ**: ç¡®ä¿ä½¿ç”¨ `main_opt.py` è€Œä¸æ˜¯ `main.py`

---

## âœ… æ£€æŸ¥æ¸…å•

åœ¨ä½¿ç”¨ OPT æ¨¡å‹å‰ï¼Œç¡®è®¤ï¼š

- [ ] ä½¿ç”¨ `main_opt.py` è„šæœ¬
- [ ] æ¨¡å‹ ID æ ¼å¼æ­£ç¡®ï¼ˆ`facebook/opt-*`ï¼‰
- [ ] GPU å†…å­˜è¶³å¤Ÿï¼ˆ6.7B éœ€è¦çº¦ 14GBï¼‰
- [ ] å·²å®‰è£… transformers >= 4.30.0
- [ ] å·²å®‰è£… accelerateï¼ˆç”¨äºå¤š GPUï¼‰

---

**æœ€åæ›´æ–°**: 2025-01-XX  
**ç»´æŠ¤è€…**: Jiajun Ji  
**é¡¹ç›®**: Wanda Hybrid Pruning

