# å‰ªææ¨¡å‹è¯„ä¼°æŒ‡å—

## ğŸ“ å‰ªææ¨¡å‹ä½ç½®

ä½ çš„å‰ªæåçš„Llama-2-7bæ¨¡å‹å·²ä¿å­˜åœ¨:

```
/home/jjji/Research/Hybird-Kernel/wanda/out/llama2_7b/unstructured/wanda/pruned_model/
```

### æ¨¡å‹æ–‡ä»¶ç»“æ„

```
pruned_model/
â”œâ”€â”€ config.json                          # æ¨¡å‹é…ç½®
â”œâ”€â”€ generation_config.json               # ç”Ÿæˆé…ç½®
â”œâ”€â”€ pytorch_model-00001-of-00002.bin    # æ¨¡å‹æƒé‡(ç¬¬1éƒ¨åˆ†)
â”œâ”€â”€ pytorch_model-00002-of-00002.bin    # æ¨¡å‹æƒé‡(ç¬¬2éƒ¨åˆ†)
â”œâ”€â”€ pytorch_model.bin.index.json        # æƒé‡ç´¢å¼•
â”œâ”€â”€ special_tokens_map.json             # ç‰¹æ®Štokenæ˜ å°„
â”œâ”€â”€ tokenizer.json                       # tokenizeré…ç½®
â”œâ”€â”€ tokenizer.model                      # tokenizeræ¨¡å‹
â””â”€â”€ tokenizer_config.json               # tokenizeré…ç½®
```

## ğŸ“Š å‰ªæç»“æœ

æ ¹æ®ä½ çš„è¾“å‡º:

- **ç¨€ç–åº¦**: 50.00% (æ¯å±‚éƒ½æ˜¯ç²¾ç¡®çš„50%ç¨€ç–åº¦)
- **WikiTextå›°æƒ‘åº¦**: **6.306** 
- **è®ºæ–‡å‚è€ƒå€¼**: 6.42 (Llama-2-7b, 50%ç¨€ç–åº¦)

**ç»“è®º**: ä½ çš„å‰ªææ•ˆæœ**éå¸¸å¥½**,ç”šè‡³ç•¥ä¼˜äºè®ºæ–‡æŠ¥å‘Šçš„ç»“æœ! ğŸ‰

## ğŸš€ ä½¿ç”¨lm-evaluation-harnessè¯„ä¼°

### æ–¹æ³•1: ä½¿ç”¨æä¾›çš„è„šæœ¬(æ¨è)

#### ç®€å•è¯„ä¼°(ä»…WikiText)

```bash
cd /home/jjji/Research/Hybird-Kernel/wanda
chmod +x evaluate_wikitext_simple.sh
./evaluate_wikitext_simple.sh
```

#### å®Œæ•´è¯„ä¼°(WikiText + å¤šä¸ªåŸºå‡†æµ‹è¯•)

```bash
cd /home/jjji/Research/Hybird-Kernel/wanda
chmod +x evaluate_pruned_model.sh
./evaluate_pruned_model.sh
```

### æ–¹æ³•2: æ‰‹åŠ¨è¿è¡Œå‘½ä»¤

#### è¯„ä¼°WikiText

```bash
cd /home/jjji/Research/Hybird-Kernel/lm-evaluation-harness

lm_eval --model hf \
    --model_args pretrained=/home/jjji/Research/Hybird-Kernel/wanda/out/llama2_7b/unstructured/wanda/pruned_model,dtype=float16 \
    --tasks wikitext \
    --device cuda:0 \
    --batch_size auto \
    --output_path /home/jjji/Research/Hybird-Kernel/wanda/out/llama2_7b/unstructured/wanda/eval_results
```

#### è¯„ä¼°å¤šä¸ªåŸºå‡†æµ‹è¯•

```bash
lm_eval --model hf \
    --model_args pretrained=/home/jjji/Research/Hybird-Kernel/wanda/out/llama2_7b/unstructured/wanda/pruned_model,dtype=float16 \
    --tasks hellaswag,piqa,winogrande,arc_easy,arc_challenge,boolq,rte,openbookqa \
    --device cuda:0 \
    --batch_size auto \
    --output_path /home/jjji/Research/Hybird-Kernel/wanda/out/llama2_7b/unstructured/wanda/eval_results
```

## ğŸ“‹ æ”¯æŒçš„è¯„ä¼°ä»»åŠ¡

### å¸¸ç”¨åŸºå‡†æµ‹è¯•

| ä»»åŠ¡ | è¯´æ˜ | è¯„ä¼°æŒ‡æ ‡ |
|------|------|---------|
| `wikitext` | WikiTextè¯­è¨€å»ºæ¨¡ | Perplexity (å›°æƒ‘åº¦) |
| `hellaswag` | å¸¸è¯†æ¨ç† | Accuracy |
| `piqa` | ç‰©ç†å¸¸è¯†é—®ç­” | Accuracy |
| `winogrande` | ä»£è¯æ¶ˆæ­§ | Accuracy |
| `arc_easy` | ARCç®€å•ç‰ˆ | Accuracy |
| `arc_challenge` | ARCæŒ‘æˆ˜ç‰ˆ | Accuracy |
| `boolq` | å¸ƒå°”é—®ç­” | Accuracy |
| `rte` | æ–‡æœ¬è•´å« | Accuracy |
| `openbookqa` | å¼€æ”¾ä¹¦ç±é—®ç­” | Accuracy |

### æŸ¥çœ‹æ‰€æœ‰å¯ç”¨ä»»åŠ¡

```bash
cd /home/jjji/Research/Hybird-Kernel/lm-evaluation-harness
lm_eval --tasks list
```

## ğŸ”§ å‘½ä»¤å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `--model` | æ¨¡å‹ç±»å‹ | `hf` (HuggingFace) |
| `--model_args` | æ¨¡å‹å‚æ•° | `pretrained=<path>,dtype=float16` |
| `--tasks` | è¯„ä¼°ä»»åŠ¡ | `wikitext` æˆ– `hellaswag,piqa` |
| `--device` | è®¡ç®—è®¾å¤‡ | `cuda:0` |
| `--batch_size` | æ‰¹æ¬¡å¤§å° | `auto` (è‡ªåŠ¨), `8`, `16` ç­‰ |
| `--output_path` | ç»“æœä¿å­˜è·¯å¾„ | `/path/to/output` |
| `--num_fewshot` | Few-shotæ ·æœ¬æ•° | `0` (zero-shot), `5` ç­‰ |

## ğŸ“ˆ é¢„æœŸè¯„ä¼°æ—¶é—´

åŸºäºLlama-2-7bæ¨¡å‹:

- **WikiText**: ~5-10åˆ†é’Ÿ
- **å•ä¸ªåŸºå‡†æµ‹è¯•**: ~10-20åˆ†é’Ÿ
- **å®Œæ•´è¯„ä¼°(8ä¸ªä»»åŠ¡)**: ~1-2å°æ—¶

## ğŸ” æŸ¥çœ‹è¯„ä¼°ç»“æœ

è¯„ä¼°å®Œæˆå,ç»“æœä¼šä¿å­˜åœ¨æŒ‡å®šçš„è¾“å‡ºç›®å½•:

```bash
# æŸ¥çœ‹ç»“æœç›®å½•
ls -lh /home/jjji/Research/Hybird-Kernel/wanda/out/llama2_7b/unstructured/wanda/eval_results/

# æŸ¥çœ‹JSONç»“æœ
cat /home/jjji/Research/Hybird-Kernel/wanda/out/llama2_7b/unstructured/wanda/eval_results/results.json
```

ç»“æœæ–‡ä»¶é€šå¸¸åŒ…æ‹¬:
- `results.json`: è¯¦ç»†çš„è¯„ä¼°ç»“æœ
- `samples_*.jsonl`: æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ
- æ—¥å¿—æ–‡ä»¶

## ğŸ“Š ä¸åŸå§‹æ¨¡å‹å¯¹æ¯”

### åˆ›å»ºå¯¹æ¯”è¯„ä¼°

å¦‚æœä½ æƒ³å¯¹æ¯”å‰ªæå‰åçš„æ€§èƒ½:

```bash
# è¯„ä¼°åŸå§‹æ¨¡å‹
lm_eval --model hf \
    --model_args pretrained=/mnt/sdb/llm_models/Llama-2-7b-hf,dtype=float16 \
    --tasks wikitext,hellaswag,piqa \
    --device cuda:0 \
    --batch_size auto \
    --output_path /home/jjji/Research/Hybird-Kernel/wanda/out/llama2_7b/dense_baseline

# è¯„ä¼°å‰ªææ¨¡å‹
lm_eval --model hf \
    --model_args pretrained=/home/jjji/Research/Hybird-Kernel/wanda/out/llama2_7b/unstructured/wanda/pruned_model,dtype=float16 \
    --tasks wikitext,hellaswag,piqa \
    --device cuda:0 \
    --batch_size auto \
    --output_path /home/jjji/Research/Hybird-Kernel/wanda/out/llama2_7b/pruned_50
```

## ğŸ ä½¿ç”¨Python APIè¯„ä¼°

å¦‚æœä½ æƒ³åœ¨Pythonä»£ç ä¸­ä½¿ç”¨:

```python
import lm_eval
from lm_eval.models.huggingface import HFLM

# åŠ è½½å‰ªææ¨¡å‹
model_path = "/home/jjji/Research/Hybird-Kernel/wanda/out/llama2_7b/unstructured/wanda/pruned_model"
model = HFLM(pretrained=model_path, dtype="float16")

# è¿è¡Œè¯„ä¼°
results = lm_eval.simple_evaluate(
    model=model,
    tasks=["wikitext", "hellaswag"],
    num_fewshot=0,
    batch_size="auto"
)

# æ‰“å°ç»“æœ
print(results["results"])
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### é—®é¢˜1: æ‰¾ä¸åˆ°æ¨¡å‹

**é”™è¯¯**: `OSError: /path/to/model does not appear to be a valid model`

**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®
```bash
ls -lh /home/jjji/Research/Hybird-Kernel/wanda/out/llama2_7b/unstructured/wanda/pruned_model/
```

### é—®é¢˜2: CUDAå†…å­˜ä¸è¶³

**é”™è¯¯**: `CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**: å‡å°batch size
```bash
lm_eval ... --batch_size 4  # æˆ–æ›´å°çš„å€¼
```

### é—®é¢˜3: lm_evalå‘½ä»¤æ‰¾ä¸åˆ°

**é”™è¯¯**: `command not found: lm_eval`

**è§£å†³æ–¹æ¡ˆ**: å®‰è£…lm-evaluation-harness
```bash
cd /home/jjji/Research/Hybird-Kernel/lm-evaluation-harness
pip install -e .
```

## ğŸ“š å‚è€ƒèµ„æ–™

- **lm-evaluation-harnessæ–‡æ¡£**: [GitHub](https://github.com/EleutherAI/lm-evaluation-harness)
- **Wandaè®ºæ–‡**: [arXiv:2306.11695](https://arxiv.org/abs/2306.11695)
- **Llama-2è®ºæ–‡**: [arXiv:2307.09288](https://arxiv.org/abs/2307.09288)

## âœ… å¿«é€Ÿæ£€æŸ¥æ¸…å•

- [x] å‰ªæå®Œæˆ (ç¨€ç–åº¦: 50%, PPL: 6.306)
- [x] æ¨¡å‹å·²ä¿å­˜
- [ ] å®‰è£…lm-evaluation-harness
- [ ] è¿è¡ŒWikiTextè¯„ä¼°
- [ ] è¿è¡ŒåŸºå‡†æµ‹è¯•è¯„ä¼°
- [ ] å¯¹æ¯”åŸå§‹æ¨¡å‹æ€§èƒ½
- [ ] ä¿å­˜è¯„ä¼°ç»“æœ

## ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®

1. **åŸºç¡€è¯„ä¼°**: å…ˆè¿è¡ŒWikiTextè¯„ä¼°,éªŒè¯æ¨¡å‹åŠ è½½æ­£ç¡®
2. **æ‰©å±•è¯„ä¼°**: è¿è¡Œå¸¸ç”¨åŸºå‡†æµ‹è¯•(HellaSwag, PIQAç­‰)
3. **æ€§èƒ½å¯¹æ¯”**: ä¸åŸå§‹denseæ¨¡å‹å¯¹æ¯”æ€§èƒ½ä¸‹é™
4. **åº”ç”¨æµ‹è¯•**: åœ¨ä½ çš„å…·ä½“åº”ç”¨åœºæ™¯ä¸­æµ‹è¯•æ¨¡å‹

## ğŸ¯ é¢„æœŸæ€§èƒ½å‚è€ƒ

æ ¹æ®Wandaè®ºæ–‡,Llama-2-7båœ¨50%ç¨€ç–åº¦ä¸‹çš„é¢„æœŸæ€§èƒ½:

| ä»»åŠ¡ | Dense | Wanda 50% | ä½ çš„ç»“æœ |
|------|-------|-----------|---------|
| WikiText PPL | 5.12 | 6.42 | **6.31** âœ… |
| HellaSwag | - | - | å¾…è¯„ä¼° |
| PIQA | - | - | å¾…è¯„ä¼° |
| WinoGrande | - | - | å¾…è¯„ä¼° |

ä½ çš„WikiTextç»“æœå·²ç»**ä¼˜äºè®ºæ–‡æŠ¥å‘Šå€¼**! ğŸ‰

