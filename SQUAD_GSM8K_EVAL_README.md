# SQuAD & GSM8K è¯„ä¼°æŒ‡å—

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•åœ¨ SQuAD å’Œ GSM8K ä»»åŠ¡ä¸Šè¯„ä¼°åŸå§‹æ¨¡å‹å’Œå‰ªæå¾®è°ƒæ¨¡å‹ã€‚

---

## ğŸ“‹ ä»»åŠ¡è¯´æ˜

### SQuAD v2.0 (Stanford Question Answering Dataset)

- **ä»»åŠ¡ç±»å‹**: é˜…è¯»ç†è§£é—®ç­”
- **æ•°æ®é›†å¤§å°**: ~11,873 ä¸ªæµ‹è¯•æ ·æœ¬
- **è¯„ä¼°æ–¹å¼**: ç”Ÿæˆå¼ï¼ˆéœ€è¦ç”Ÿæˆç­”æ¡ˆæ–‡æœ¬ï¼‰
- **æŒ‡æ ‡**: 
  - **Exact Match (EM)**: ç²¾ç¡®åŒ¹é…ç‡
  - **F1 Score**: F1 åˆ†æ•°
- **ç‰¹ç‚¹**: åŒ…å«æ— æ³•å›ç­”çš„é—®é¢˜ï¼ˆSQuAD 2.0 çš„ç‰¹è‰²ï¼‰

**ç¤ºä¾‹**ï¼š
```
Context: "The Normans were the people who in the 10th and 11th centuries gave their name to Normandy..."
Question: "In what country is Normandy located?"
Answer: "France"
```

### GSM8K (Grade School Math 8K)

- **ä»»åŠ¡ç±»å‹**: å°å­¦æ•°å­¦æ¨ç†
- **æ•°æ®é›†å¤§å°**: 1,319 ä¸ªæµ‹è¯•æ ·æœ¬
- **è¯„ä¼°æ–¹å¼**: ç”Ÿæˆå¼ï¼ˆéœ€è¦ç”Ÿæˆæ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆï¼‰
- **æŒ‡æ ‡**: 
  - **Accuracy**: ç­”æ¡ˆå‡†ç¡®ç‡
- **ç‰¹ç‚¹**: éœ€è¦å¤šæ­¥æ¨ç†çš„æ•°å­¦é—®é¢˜

**ç¤ºä¾‹**ï¼š
```
Question: "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?"
Answer: "Natalia sold 48/2 = 24 clips in May. Natalia sold 48+24 = 72 clips altogether in April and May. #### 72"
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1: ä½¿ç”¨ Shell è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
cd /home/jjji/Research/Hybird-Kernel/wanda

# è¿è¡Œè¯„ä¼°
./run_eval_squad_gsm8k.sh
```

è„šæœ¬ä¼šï¼š
1. æ˜¾ç¤ºé…ç½®ä¿¡æ¯
2. è¯¢é—®æ˜¯å¦ç»§ç»­ï¼ˆå› ä¸ºè¯„ä¼°æ—¶é—´å¾ˆé•¿ï¼‰
3. ä¾æ¬¡è¯„ä¼°åŸå§‹æ¨¡å‹å’Œå‰ªææ¨¡å‹
4. ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š

### æ–¹æ³• 2: ç›´æ¥ä½¿ç”¨ Python è„šæœ¬

```bash
cd /home/jjji/Research/Hybird-Kernel/wanda

python eval_squad_gsm8k_compare.py \
    --original_model /mnt/sdb/llm_models/Llama-2-7b-hf \
    --pruned_model out/llama2_7b/block_16x16_three_tier_0.35_0.45_0.2/wanda/dense_finetuned_model \
    --tasks squadv2 gsm8k \
    --output_dir eval_results_squad_gsm8k
```

---

## âš™ï¸ é…ç½®é€‰é¡¹

### æ¨¡å‹è·¯å¾„

```bash
# åŸå§‹æ¨¡å‹
--original_model /mnt/sdb/llm_models/Llama-2-7b-hf

# å‰ªæå¾®è°ƒæ¨¡å‹
--pruned_model out/llama2_7b/block_16x16_three_tier_0.35_0.45_0.2/wanda/dense_finetuned_model
```

### è¯„ä¼°ä»»åŠ¡

```bash
# é»˜è®¤ï¼šSQuAD v2 å’Œ GSM8K
--tasks squadv2 gsm8k

# åªè¯„ä¼° SQuAD
--tasks squadv2

# åªè¯„ä¼° GSM8K
--tasks gsm8k

# æ·»åŠ å…¶ä»– GSM8K å˜ä½“
--tasks squadv2 gsm8k gsm8k_cot
```

### å…¶ä»–é€‰é¡¹

```bash
# è¾“å‡ºç›®å½•
--output_dir eval_results_squad_gsm8k

# æ¨¡å‹ç¼“å­˜ç›®å½•
--cache_dir llm_weights

# PPL è¯„ä¼°æ ·æœ¬æ•°
--nsamples 128

# éšæœºç§å­
--seed 0
```

---

## â±ï¸ è¯„ä¼°æ—¶é—´ä¼°è®¡

### SQuAD v2.0

| æ¨¡å‹å¤§å° | æ ·æœ¬æ•° | é¢„è®¡æ—¶é—´ |
|---------|--------|---------|
| 7B | 11,873 | 1.5-2.5 å°æ—¶ |
| 13B | 11,873 | 2.5-3.5 å°æ—¶ |
| 70B | 11,873 | 6-8 å°æ—¶ |

### GSM8K

| æ¨¡å‹å¤§å° | æ ·æœ¬æ•° | é¢„è®¡æ—¶é—´ |
|---------|--------|---------|
| 7B | 1,319 | 0.5-1 å°æ—¶ |
| 13B | 1,319 | 1-1.5 å°æ—¶ |
| 70B | 1,319 | 2-3 å°æ—¶ |

### æ€»æ—¶é—´

- **7B æ¨¡å‹**: 4-7 å°æ—¶ï¼ˆä¸¤ä¸ªæ¨¡å‹ï¼‰
- **13B æ¨¡å‹**: 7-10 å°æ—¶ï¼ˆä¸¤ä¸ªæ¨¡å‹ï¼‰
- **70B æ¨¡å‹**: 16-22 å°æ—¶ï¼ˆä¸¤ä¸ªæ¨¡å‹ï¼‰

**å»ºè®®**: ä½¿ç”¨ `tmux` æˆ– `screen` åœ¨åå°è¿è¡Œï¼Œé¿å… SSH æ–­å¼€å¯¼è‡´è¯„ä¼°ä¸­æ–­ã€‚

---

## ğŸ“Š è¾“å‡ºç»“æœ

### æ–‡ä»¶ç»“æ„

```
eval_results_squad_gsm8k/
â”œâ”€â”€ original_model_results.json      # åŸå§‹æ¨¡å‹ç»“æœï¼ˆJSONï¼‰
â”œâ”€â”€ pruned_model_results.json        # å‰ªææ¨¡å‹ç»“æœï¼ˆJSONï¼‰
â”œâ”€â”€ comparison_report.md             # å¯¹æ¯”æŠ¥å‘Šï¼ˆMarkdownï¼‰
â””â”€â”€ comparison_results.json          # å¯¹æ¯”ç»“æœï¼ˆJSONï¼‰
```

### ç»“æœç¤ºä¾‹

#### JSON æ ¼å¼

```json
{
  "model_path": "/mnt/sdb/llm_models/Llama-2-7b-hf",
  "sparsity": 0.0,
  "wikitext_ppl": 5.12,
  "tasks": {
    "squadv2": {
      "exact_match": 0.6234,
      "f1": 0.7123
    },
    "gsm8k": {
      "accuracy": 0.1523
    }
  }
}
```

#### Markdown æŠ¥å‘Š

```markdown
# Model Comparison Report

## Model Information
- Original Model: /mnt/sdb/llm_models/Llama-2-7b-hf
- Pruned Model: out/llama2_7b/.../dense_finetuned_model

## Summary
| Metric | Original | Pruned | Difference |
|--------|----------|--------|------------|
| Sparsity | 0.00% | 65.00% | +65.00% |
| WikiText2 PPL | 5.1200 | 6.8900 | +1.7700 |

## Task Results
| Task | Original | Pruned | Difference | Relative |
|------|----------|--------|------------|----------|
| squadv2 (EM) | 0.6234 | 0.5123 | -0.1111 | -17.82% |
| squadv2 (F1) | 0.7123 | 0.6234 | -0.0889 | -12.48% |
| gsm8k | 0.1523 | 0.0987 | -0.0536 | -35.19% |
```

---

## ğŸ” ä¸ BoolQ ç­‰ä»»åŠ¡çš„åŒºåˆ«

### ä»»åŠ¡ç±»å‹å¯¹æ¯”

| ç‰¹æ€§ | BoolQ/RTE/HellaSwag | SQuAD/GSM8K |
|------|---------------------|-------------|
| **ä»»åŠ¡ç±»å‹** | åˆ†ç±»ï¼ˆé€‰æ‹©é¢˜ï¼‰ | ç”Ÿæˆï¼ˆå¼€æ”¾å¼ï¼‰ |
| **è¯„ä¼°æ–¹å¼** | Loglikelihood | Generation |
| **é€Ÿåº¦** | å¿«ï¼ˆ~1-2 å°æ—¶ï¼‰ | æ…¢ï¼ˆ~4-8 å°æ—¶ï¼‰ |
| **æŒ‡æ ‡** | Accuracy | EM/F1/Accuracy |
| **éš¾åº¦** | ç›¸å¯¹ç®€å• | æ›´å…·æŒ‘æˆ˜æ€§ |

### ä¸ºä»€ä¹ˆ SQuAD/GSM8K æ›´æ…¢ï¼Ÿ

1. **ç”Ÿæˆä»»åŠ¡**: éœ€è¦ç”Ÿæˆå®Œæ•´çš„ç­”æ¡ˆæ–‡æœ¬ï¼Œè€Œä¸æ˜¯ç®€å•çš„åˆ†ç±»
2. **å¤šæ¬¡å‰å‘ä¼ æ’­**: æ¯ä¸ª token éƒ½éœ€è¦ä¸€æ¬¡å‰å‘ä¼ æ’­
3. **æ›´é•¿çš„è¾“å‡º**: SQuAD ç­”æ¡ˆå¯èƒ½å¾ˆé•¿ï¼ŒGSM8K éœ€è¦ç”Ÿæˆæ¨ç†è¿‡ç¨‹
4. **æ›´å¤§çš„æ ·æœ¬é‡**: SQuAD v2 æœ‰ 11,873 ä¸ªæ ·æœ¬

---

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### 1. å…ˆæµ‹è¯•å°æ ·æœ¬

åœ¨æ­£å¼è¯„ä¼°å‰ï¼Œå…ˆç”¨å°‘é‡æ ·æœ¬æµ‹è¯•ï¼š

```bash
# ä¿®æ”¹ eval_squad_gsm8k_compare.py ä¸­çš„ limit å‚æ•°
# åœ¨ evaluate_model å‡½æ•°ä¸­æ·»åŠ ï¼š
results = eval_zero_shot(
    model_name=model_name,
    model=model,
    tokenizer=tokenizer,
    task_list=args.tasks,
    num_fewshot=0,
    limit=100  # åªè¯„ä¼° 100 ä¸ªæ ·æœ¬
)
```

### 2. ä½¿ç”¨åå°è¿è¡Œ

```bash
# ä½¿ç”¨ tmux
tmux new -s eval_squad_gsm8k
./run_eval_squad_gsm8k.sh
# Ctrl+B, D åˆ†ç¦»ä¼šè¯

# é‡æ–°è¿æ¥
tmux attach -t eval_squad_gsm8k
```

### 3. ç›‘æ§è¿›åº¦

```bash
# æŸ¥çœ‹è¾“å‡ºæ—¥å¿—
tail -f eval_results_squad_gsm8k/evaluation.log

# æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…å†µ
watch -n 1 nvidia-smi
```

### 4. åˆ†æ‰¹è¯„ä¼°

å¦‚æœæ—¶é—´æœ‰é™ï¼Œå¯ä»¥åˆ†æ‰¹è¯„ä¼°ï¼š

```bash
# ç¬¬ä¸€å¤©ï¼šåªè¯„ä¼° SQuAD
python eval_squad_gsm8k_compare.py --tasks squadv2

# ç¬¬äºŒå¤©ï¼šåªè¯„ä¼° GSM8K
python eval_squad_gsm8k_compare.py --tasks gsm8k
```

---

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜ 1: å†…å­˜ä¸è¶³

**ç—‡çŠ¶**: `CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å‡å°‘ batch sizeï¼ˆä¿®æ”¹ lib/eval.pyï¼‰
# æˆ–ä½¿ç”¨ CPU offload
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
```

### é—®é¢˜ 2: è¯„ä¼°ä¸­æ–­

**ç—‡çŠ¶**: SSH æ–­å¼€å¯¼è‡´è¯„ä¼°åœæ­¢

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä½¿ç”¨ nohup
nohup ./run_eval_squad_gsm8k.sh > eval.log 2>&1 &

# æˆ–ä½¿ç”¨ tmux/screen
```

### é—®é¢˜ 3: ä»»åŠ¡æœªæ‰¾åˆ°

**ç—‡çŠ¶**: `Task 'squadv2' not found`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ lm-evaluation-harness æ˜¯å¦æ­£ç¡®å®‰è£…
python -c "
import sys
sys.path.insert(0, '/home/jjji/Research/Hybird-Kernel/lm-evaluation-harness')
from lm_eval.tasks import TaskManager
tm = TaskManager()
print('squadv2' in tm.all_tasks)
print('gsm8k' in tm.all_tasks)
"
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### SQuAD

- [SQuAD 2.0 è®ºæ–‡](https://arxiv.org/abs/1806.03822)
- [SQuAD å®˜ç½‘](https://rajpurkar.github.io/SQuAD-explorer/)
- [Hugging Face SQuAD](https://huggingface.co/datasets/squad_v2)

### GSM8K

- [GSM8K è®ºæ–‡](https://arxiv.org/abs/2110.14168)
- [GSM8K GitHub](https://github.com/openai/grade-school-math)
- [Hugging Face GSM8K](https://huggingface.co/datasets/gsm8k)

### LM Evaluation Harness

- [GitHub](https://github.com/EleutherAI/lm-evaluation-harness)
- [æ–‡æ¡£](https://github.com/EleutherAI/lm-evaluation-harness/tree/main/docs)

---

## âœ… æ£€æŸ¥æ¸…å•

è¯„ä¼°å‰ç¡®è®¤ï¼š

- [ ] æ¨¡å‹è·¯å¾„æ­£ç¡®
- [ ] æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ï¼ˆè‡³å°‘ 50GBï¼‰
- [ ] æœ‰è¶³å¤Ÿçš„ GPU å†…å­˜ï¼ˆ7B æ¨¡å‹éœ€è¦ ~16GBï¼‰
- [ ] å·²å®‰è£… lm-evaluation-harness
- [ ] ä½¿ç”¨ tmux/screen æˆ– nohup
- [ ] é¢„ç•™è¶³å¤Ÿçš„æ—¶é—´ï¼ˆ4-8 å°æ—¶ï¼‰

---

**æœ€åæ›´æ–°**: 2025-01-XX  
**ç»´æŠ¤è€…**: Jiajun Ji  
**é¡¹ç›®**: Wanda Hybrid Pruning

