# Wanda vs lm-eval å›°æƒ‘åº¦å·®å¼‚åˆ†æ

## ğŸ” é—®é¢˜

ä½ çš„è¯„ä¼°ç»“æœæ˜¾ç¤ºå·¨å¤§å·®å¼‚:
- **Wandaè¯„ä¼°**: PPL = **6.31** âœ…
- **lm-evalè¯„ä¼°**: PPL = **11.22** âŒ

å·®å¼‚é«˜è¾¾ **77%**! è¿™æ˜¯ä¸ºä»€ä¹ˆ?

## ğŸ“Š æ ¸å¿ƒå‘ç°

ç»è¿‡æ·±å…¥åˆ†æWandaçš„è¯„ä¼°ä»£ç ,æˆ‘å‘ç°äº†**å…³é”®å·®å¼‚**:

### 1ï¸âƒ£ æ•°æ®é¢„å¤„ç†æ–¹å¼ä¸åŒ

#### Wandaçš„æ–¹å¼ (`lib/data.py` ç¬¬26è¡Œ)

```python
# Wandaä½¿ç”¨ "\n\n" è¿æ¥æµ‹è¯•æ•°æ®
testenc = tokenizer("\n\n".join(testdata['text']), return_tensors='pt')
```

#### lm-evalçš„æ–¹å¼

lm-evalå¯èƒ½ä½¿ç”¨ä¸åŒçš„è¿æ¥æ–¹å¼æˆ–æ•°æ®å¤„ç†æµç¨‹ã€‚

### 2ï¸âƒ£ è¯„ä¼°æ–¹æ³•çš„è¯¦ç»†å¯¹æ¯”

<augment_code_snippet path="wanda/lib/eval.py" mode="EXCERPT">
````python
def eval_ppl_wikitext(model, testenc, bs=1, device=None):
    # è·å–input IDs
    testenc = testenc.input_ids
    
    # è®¡ç®—æ ·æœ¬æ•° (å…³é”®!)
    nsamples = testenc.numel() // model.seqlen
    
    # å­˜å‚¨è´Ÿå¯¹æ•°ä¼¼ç„¶
    nlls = []
    
    # æŒ‰å›ºå®šåºåˆ—é•¿åº¦åˆ†å—è¯„ä¼°
    for i in range(0, nsamples, bs):
        j = min(i+bs, nsamples)
        
        # å‡†å¤‡è¾“å…¥ (å›ºå®šé•¿åº¦åˆ‡ç‰‡)
        inputs = testenc[:, (i * model.seqlen):(j * model.seqlen)].to(device)
        inputs = inputs.reshape(j-i, model.seqlen)
        
        # å‰å‘ä¼ æ’­
        lm_logits = model(inputs).logits
        
        # è®¡ç®—loss
        shift_logits = lm_logits[:, :-1, :].contiguous()
        shift_labels = inputs[:, 1:]
        loss_fct = nn.CrossEntropyLoss()
        loss = loss_fct(shift_logits.reshape(-1, shift_logits.size(-1)), 
                       shift_labels.reshape(-1))
        
        # ç´¯ç§¯è´Ÿå¯¹æ•°ä¼¼ç„¶
        neg_log_likelihood = loss.float() * model.seqlen * (j-i)
        nlls.append(neg_log_likelihood)
    
    # è®¡ç®—å›°æƒ‘åº¦
    ppl = torch.exp(torch.stack(nlls).sum() / (nsamples * model.seqlen))
    
    return ppl.item()
````
</augment_code_snippet>

### 3ï¸âƒ£ å…³é”®å·®å¼‚ç‚¹

| ç»´åº¦ | Wandaè¯„ä¼° | lm-evalè¯„ä¼° |
|------|----------|------------|
| **æ•°æ®è¿æ¥** | `"\n\n".join()` | å¯èƒ½ä¸åŒ |
| **åºåˆ—é•¿åº¦** | å›ºå®š `model.seqlen` (2048) | å¯èƒ½ä¸åŒ |
| **åˆ†å—æ–¹å¼** | å›ºå®šé•¿åº¦åˆ‡ç‰‡,æ— é‡å  | å¯èƒ½æœ‰stride/overlap |
| **lossè®¡ç®—** | æ ‡å‡†CrossEntropyLoss | å¯èƒ½ç›¸åŒ |
| **PPLè®¡ç®—** | `exp(sum(nlls) / total_tokens)` | å¯èƒ½ä¸åŒ |
| **æ•°æ®é›†ç‰ˆæœ¬** | `wikitext-2-raw-v1` | å¯èƒ½ä¸åŒ |

## ğŸ”¬ æ·±å…¥åˆ†æ

### Wandaçš„è¯„ä¼°æµç¨‹

```
1. åŠ è½½WikiText2æµ‹è¯•é›†
   â†“
2. ä½¿ç”¨ "\n\n" è¿æ¥æ‰€æœ‰æ–‡æœ¬
   testenc = tokenizer("\n\n".join(testdata['text']))
   â†“
3. è®¡ç®—æ ·æœ¬æ•°
   nsamples = total_tokens // seqlen
   â†“
4. æŒ‰å›ºå®šé•¿åº¦(seqlen=2048)åˆ‡ç‰‡
   inputs = testenc[:, i*seqlen : (i+1)*seqlen]
   â†“
5. è®¡ç®—æ¯ä¸ªåˆ‡ç‰‡çš„loss
   â†“
6. ç´¯ç§¯æ‰€æœ‰è´Ÿå¯¹æ•°ä¼¼ç„¶
   total_nll = sum(nlls)
   â†“
7. è®¡ç®—å›°æƒ‘åº¦
   ppl = exp(total_nll / total_tokens)
```

### å¯èƒ½å¯¼è‡´å·®å¼‚çš„åŸå› 

#### åŸå› 1: æ•°æ®é¢„å¤„ç†å·®å¼‚ â­â­â­

**Wanda**:
```python
testenc = tokenizer("\n\n".join(testdata['text']))
```
- ä½¿ç”¨åŒæ¢è¡Œç¬¦è¿æ¥
- å¯èƒ½ä¿ç•™äº†æ›´å¤šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
- æ–‡æœ¬ä¹‹é—´æœ‰æ˜ç¡®çš„åˆ†éš”

**lm-eval**: å¯èƒ½ä½¿ç”¨ä¸åŒçš„è¿æ¥æ–¹å¼æˆ–å¤„ç†æ¯ä¸ªæ–‡æ¡£ç‹¬ç«‹

#### åŸå› 2: åºåˆ—é•¿åº¦å’Œstride â­â­â­

**Wanda**:
- å›ºå®šé•¿åº¦åˆ‡ç‰‡: `seqlen = 2048`
- æ— é‡å : æ¯ä¸ªtokenåªè¯„ä¼°ä¸€æ¬¡
- ç®€å•é«˜æ•ˆ

**lm-eval**: å¯èƒ½ä½¿ç”¨:
- ä¸åŒçš„åºåˆ—é•¿åº¦
- Sliding window with stride
- æ¯ä¸ªtokenå¯èƒ½è¢«è¯„ä¼°å¤šæ¬¡

#### åŸå› 3: ç‰¹æ®Štokenå¤„ç† â­â­

**Wanda**:
```python
# ç®€å•çš„shiftæ“ä½œ
shift_logits = lm_logits[:, :-1, :]
shift_labels = inputs[:, 1:]
```

**lm-eval**: å¯èƒ½å¯¹ç‰¹æ®Štoken(å¦‚padding, BOS, EOS)æœ‰ä¸åŒå¤„ç†

#### åŸå› 4: æ•°æ®é›†splitæˆ–ç‰ˆæœ¬ â­

**Wanda**: æ˜ç¡®ä½¿ç”¨ `wikitext-2-raw-v1` çš„ `test` split

**lm-eval**: å¯èƒ½ä½¿ç”¨ä¸åŒç‰ˆæœ¬æˆ–split

## ğŸ§ª éªŒè¯å®éªŒ

### å®éªŒ1: æ£€æŸ¥lm-evalä½¿ç”¨çš„æ•°æ®é›†

```bash
# æŸ¥çœ‹lm-evalçš„WikiTextä»»åŠ¡å®šä¹‰
python -c "
from lm_eval import tasks
task = tasks.get_task_dict(['wikitext'])
print(task)
"
```

### å®éªŒ2: ä½¿ç”¨Wandaçš„æ–¹æ³•è¯„ä¼°åŸå§‹æ¨¡å‹

```bash
cd /home/jjji/Research/Hybird-Kernel/wanda

python -c "
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from lib.eval import eval_ppl
import argparse

# åˆ›å»ºargså¯¹è±¡
args = argparse.Namespace()

# åŠ è½½åŸå§‹æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    '/mnt/sdb/llm_models/Llama-2-7b-hf',
    torch_dtype=torch.float16,
    device_map='auto'
)
model.seqlen = 2048
tokenizer = AutoTokenizer.from_pretrained('/mnt/sdb/llm_models/Llama-2-7b-hf')

# è¯„ä¼°
device = torch.device('cuda:0')
ppl = eval_ppl(args, model, tokenizer, device)
print(f'Dense Llama-2-7b PPL (Wanda method): {ppl:.4f}')
"
```

### å®éªŒ3: å¯¹æ¯”ä¸åŒè¯„ä¼°æ–¹æ³•

åˆ›å»ºä¸€ä¸ªè„šæœ¬åŒæ—¶è¿è¡Œä¸¤ç§è¯„ä¼°æ–¹æ³•:

```python
# 1. Wandaæ–¹æ³•
ppl_wanda = eval_ppl(args, model, tokenizer, device)

# 2. lm-evalæ–¹æ³•
from lm_eval import evaluator
results = evaluator.simple_evaluate(
    model="hf",
    model_args=f"pretrained={model_path}",
    tasks=["wikitext"],
    ...
)
ppl_lmeval = results['results']['wikitext']['word_perplexity']

print(f"Wanda PPL: {ppl_wanda}")
print(f"lm-eval PPL: {ppl_lmeval}")
```

## ğŸ“ˆ é¢„æœŸç»“æœ

å¦‚æœæˆ‘çš„åˆ†ææ­£ç¡®,ä½ åº”è¯¥çœ‹åˆ°:

| æ¨¡å‹ | Wandaè¯„ä¼° | lm-evalè¯„ä¼° | å·®å¼‚ |
|------|----------|------------|------|
| Dense Llama-2-7b | ~5.12 | ~8-10? | ~60-95% |
| Pruned Llama-2-7b | 6.31 | 11.22 | 77% |

**å…³é”®è§‚å¯Ÿ**: å¦‚æœDenseæ¨¡å‹çš„å·®å¼‚æ¯”ä¾‹ä¸Prunedæ¨¡å‹ç›¸ä¼¼,è¯´æ˜è¿™æ˜¯**è¯„ä¼°æ–¹æ³•çš„ç³»ç»Ÿæ€§å·®å¼‚**,è€Œä¸æ˜¯å‰ªæå¯¼è‡´çš„é—®é¢˜ã€‚

## ğŸ’¡ ç»“è®º

### ä¸ºä»€ä¹ˆå·®å¼‚è¿™ä¹ˆå¤§?

1. **æ•°æ®é¢„å¤„ç†ä¸åŒ**: `"\n\n".join()` vs å…¶ä»–æ–¹å¼
2. **åºåˆ—åˆ‡åˆ†ç­–ç•¥ä¸åŒ**: å›ºå®šé•¿åº¦æ— é‡å  vs sliding window
3. **è¯„ä¼°ç²’åº¦ä¸åŒ**: token-level vs word-level vs byte-level
4. **ç‰¹æ®Štokenå¤„ç†ä¸åŒ**: å¯èƒ½å½±å“æœ€ç»ˆPPLè®¡ç®—

### å“ªä¸ªç»“æœæ›´å¯ä¿¡?

**Wandaçš„è¯„ä¼°ç»“æœ (6.31) æ›´å¯ä¿¡**,åŸå› :

1. âœ… **ä¸è®ºæ–‡ä¸€è‡´**: è®ºæ–‡æŠ¥å‘Š6.42,ä½ çš„6.31éå¸¸æ¥è¿‘
2. âœ… **è¯„ä¼°æ–¹æ³•ä¸€è‡´**: ä½¿ç”¨ç›¸åŒçš„ä»£ç å’Œæµç¨‹
3. âœ… **å¯å¤ç°**: å‰ªæè¿‡ç¨‹ä¸­ç›´æ¥è®¡ç®—
4. âœ… **ä¸“é—¨ä¼˜åŒ–**: Wandaçš„è¯„ä¼°æ–¹æ³•ä¸“é—¨ä¸ºLLMå‰ªæè®¾è®¡

**lm-evalçš„ç»“æœ (11.22) å¯èƒ½**:
- ä½¿ç”¨äº†ä¸åŒçš„è¯„ä¼°æ ‡å‡†
- æ›´ä¸¥æ ¼çš„è¯„ä¼°æ–¹å¼
- ä¸åŒçš„æ•°æ®å¤„ç†æµç¨‹

### å»ºè®®

1. **ä½¿ç”¨Wandaè¯„ä¼°ä½œä¸ºä¸»è¦å‚è€ƒ**: 6.31 PPL
2. **lm-evalç”¨äºzero-shotä»»åŠ¡**: HellaSwag, PIQAç­‰
3. **å¯¹æ¯”æ—¶ä¿æŒä¸€è‡´**: å¦‚æœç”¨lm-eval,Denseå’ŒPrunedéƒ½ç”¨lm-eval
4. **æŠ¥å‘Šæ—¶è¯´æ˜è¯„ä¼°æ–¹æ³•**: é¿å…æ··æ·†

## ğŸ”§ åˆ›å»ºç»Ÿä¸€è¯„ä¼°è„šæœ¬

æˆ‘å°†åˆ›å»ºä¸€ä¸ªè„šæœ¬,ä½¿ç”¨Wandaçš„æ–¹æ³•è¯„ä¼°åŸå§‹æ¨¡å‹,ä»¥ä¾¿å…¬å¹³å¯¹æ¯”...

