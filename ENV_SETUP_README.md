# Wanda é¡¹ç›®ç¯å¢ƒé…ç½®æŒ‡å—

æœ¬é¡¹ç›®åŒ…å«ä¸¤ä¸ªç‹¬ç«‹çš„ Conda ç¯å¢ƒï¼Œåˆ†åˆ«ç”¨äºä¸åŒçš„ä»»åŠ¡ã€‚

## ğŸ“¦ ç¯å¢ƒæ¦‚è§ˆ

| ç¯å¢ƒåç§° | Python | PyTorch | CUDA | ç”¨é€” |
|---------|--------|---------|------|------|
| `wanda_lora` | 3.9 | 2.8.0 | 12.8 | å¾®è°ƒã€è¯„ä¼° |
| `prune_llm` | 3.9 | 2.1.0 | 12.1 | å‰ªæã€å¯è§†åŒ– |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1ï¸âƒ£ åˆ›å»º `wanda_lora` ç¯å¢ƒï¼ˆå¾®è°ƒå’Œè¯„ä¼°ï¼‰

```bash
cd /home/jjji/Research/Hybird-Kernel/wanda
chmod +x setup_wanda_lora_env.sh
bash setup_wanda_lora_env.sh
```

**ç”¨é€”**ï¼š
- âœ… LoRA å¾®è°ƒ
- âœ… Zero-shot è¯„ä¼°ï¼ˆBoolQ, RTE, HellaSwag ç­‰ï¼‰
- âœ… lm-evaluation-harness
- âœ… æ¨¡å‹è¯„ä¼°å¯¹æ¯”

**æ¿€æ´»ç¯å¢ƒ**ï¼š
```bash
conda activate wanda_lora
```

---

### 2ï¸âƒ£ åˆ›å»º `prune_llm` ç¯å¢ƒï¼ˆå‰ªæå’Œå¯è§†åŒ–ï¼‰

```bash
cd /home/jjji/Research/Hybird-Kernel/wanda
chmod +x setup_prune_llm_env.sh
bash setup_prune_llm_env.sh
```

**ç”¨é€”**ï¼š
- âœ… Wanda å‰ªæ
- âœ… æ··åˆä¸‰å±‚å‰ªæï¼ˆDense + 2:4 + Top-Kï¼‰
- âœ… Gradio å¯è§†åŒ–ç•Œé¢
- âœ… WandB å®éªŒè·Ÿè¸ª

**æ¿€æ´»ç¯å¢ƒ**ï¼š
```bash
conda activate prune_llm
```

---

## ğŸ“‹ ç¯å¢ƒè¯¦ç»†è¯´æ˜

### `wanda_lora` ç¯å¢ƒ

**æ ¸å¿ƒä¾èµ–**ï¼š
- `torch==2.8.0` (CUDA 12.8)
- `transformers==4.57.1`
- `peft==0.6.0`
- `datasets==4.3.0`
- `evaluate==0.4.6`
- `sacrebleu==2.5.1`
- `lm-evaluation-harness` ç›¸å…³ä¾èµ–

**é€‚ç”¨è„šæœ¬**ï¼š
```bash
# å¾®è°ƒ
python finetune_lora.py

# è¯„ä¼°å¯¹æ¯”
python eval_zero_shot_compare.py

# æµ‹è¯• lm_eval
python test_lm_eval_import.py
```

---

### `prune_llm` ç¯å¢ƒ

**æ ¸å¿ƒä¾èµ–**ï¼š
- `torch==2.1.0` (CUDA 12.1)
- `transformers==4.35.2`
- `peft==0.6.0`
- `gradio==3.24.1`
- `wandb==0.22.2`
- `matplotlib==3.9.4`

**é€‚ç”¨è„šæœ¬**ï¼š
```bash
# Wanda å‰ªæ
python main.py

# ä¸‰å±‚æ··åˆå‰ªæ
python main_block_three_tier.py
python main_progressive_three_tier.py

# å¯è§†åŒ–
python gradio_app.py  # å¦‚æœæœ‰çš„è¯
```

---

## ğŸ”§ æ‰‹åŠ¨å®‰è£… lm-evaluation-harness

å¦‚æœéœ€è¦åœ¨ `wanda_lora` ç¯å¢ƒä¸­ä½¿ç”¨ lm-evaluation-harnessï¼š

```bash
conda activate wanda_lora
cd /home/jjji/Research/Hybird-Kernel/lm-evaluation-harness
pip install -e .
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. PyTorch ç‰ˆæœ¬å·®å¼‚

ä¸¤ä¸ªç¯å¢ƒä½¿ç”¨ä¸åŒçš„ PyTorch ç‰ˆæœ¬ï¼š
- `wanda_lora`: PyTorch 2.8.0 (CUDA 12.8) - æœ€æ–°ç‰ˆæœ¬ï¼Œæ”¯æŒæœ€æ–°ç‰¹æ€§
- `prune_llm`: PyTorch 2.1.0 (CUDA 12.1) - ç¨³å®šç‰ˆæœ¬ï¼Œå…¼å®¹æ€§å¥½

**å»ºè®®**ï¼š
- å¾®è°ƒå’Œè¯„ä¼°ä½¿ç”¨ `wanda_lora`
- å‰ªæä½¿ç”¨ `prune_llm`
- ä¸è¦æ··ç”¨ç¯å¢ƒ

### 2. Transformers ç‰ˆæœ¬å·®å¼‚

- `wanda_lora`: transformers 4.57.1 (æœ€æ–°)
- `prune_llm`: transformers 4.35.2 (ç¨³å®š)

**å½±å“**ï¼š
- API å¯èƒ½æœ‰ç»†å¾®å·®å¼‚
- æ¨¡å‹åŠ è½½æ–¹å¼å¯èƒ½ä¸åŒ
- å»ºè®®åœ¨åŒä¸€ç¯å¢ƒä¸­å®Œæˆå®Œæ•´æµç¨‹

### 3. CUDA å…¼å®¹æ€§

ç¡®ä¿ä½ çš„ GPU é©±åŠ¨æ”¯æŒï¼š
- CUDA 12.8 (wanda_lora)
- CUDA 12.1 (prune_llm)

æ£€æŸ¥ CUDA ç‰ˆæœ¬ï¼š
```bash
nvidia-smi
```

---

## ğŸ§ª éªŒè¯ç¯å¢ƒ

### éªŒè¯ `wanda_lora`

```bash
conda activate wanda_lora
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"
python -c "import transformers; print(f'Transformers: {transformers.__version__}')"
python test_lm_eval_import.py
```

### éªŒè¯ `prune_llm`

```bash
conda activate prune_llm
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.cuda.is_available()}')"
python -c "import transformers; print(f'Transformers: {transformers.__version__}')"
python -c "import gradio; print(f'Gradio: {gradio.__version__}')"
```

---

## ğŸ“ å¸¸è§é—®é¢˜

### Q1: å®‰è£…å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œä½¿ç”¨å›½å†…é•œåƒï¼š
```bash
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple <package>
```

### Q2: CUDA ç‰ˆæœ¬ä¸åŒ¹é…ï¼Ÿ

**A**: æ ¹æ®ä½ çš„ GPU é©±åŠ¨è°ƒæ•´ PyTorch ç‰ˆæœ¬ï¼š
```bash
# æŸ¥çœ‹æ”¯æŒçš„ CUDA ç‰ˆæœ¬
nvidia-smi

# å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„ PyTorch
pip install torch==2.1.0 --index-url https://download.pytorch.org/whl/cu118  # CUDA 11.8
```

### Q3: ä¸¤ä¸ªç¯å¢ƒå¯ä»¥å…±å­˜å—ï¼Ÿ

**A**: å¯ä»¥ï¼Conda ç¯å¢ƒæ˜¯å®Œå…¨éš”ç¦»çš„ï¼Œäº’ä¸å½±å“ã€‚

---

## ğŸ”„ æ›´æ–°ç¯å¢ƒ

å¦‚æœéœ€è¦æ›´æ–°æŸä¸ªåŒ…ï¼š

```bash
conda activate <env_name>
pip install --upgrade <package_name>
```

å¦‚æœéœ€è¦é‡å»ºç¯å¢ƒï¼š

```bash
conda remove -n <env_name> --all
bash setup_<env_name>_env.sh
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [PyTorch å®‰è£…æŒ‡å—](https://pytorch.org/get-started/locally/)
- [Transformers æ–‡æ¡£](https://huggingface.co/docs/transformers)
- [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness)
- [PEFT æ–‡æ¡£](https://huggingface.co/docs/peft)

---

## ğŸ’¡ æ¨èå·¥ä½œæµç¨‹

### å®Œæ•´çš„å‰ªæ + å¾®è°ƒ + è¯„ä¼°æµç¨‹

```bash
# 1. å‰ªæ (ä½¿ç”¨ prune_llm ç¯å¢ƒ)
conda activate prune_llm
python main_block_three_tier.py --model llama-2-7b --sparsity_ratios 0.35 0.45 0.2

# 2. å¾®è°ƒ (åˆ‡æ¢åˆ° wanda_lora ç¯å¢ƒ)
conda activate wanda_lora
python finetune_lora.py --model_path out/llama2_7b/.../pruned_model

# 3. è¯„ä¼° (ç»§ç»­ä½¿ç”¨ wanda_lora ç¯å¢ƒ)
python eval_zero_shot_compare.py \
    --original_model /mnt/sdb/llm_models/Llama-2-7b-hf \
    --pruned_model out/llama2_7b/.../dense_finetuned_model
```

---

**åˆ›å»ºæ—¶é—´**: 2025-01-XX  
**ç»´æŠ¤è€…**: Jiajun Ji  
**é¡¹ç›®**: Wanda Hybrid Pruning

