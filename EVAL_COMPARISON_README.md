# Zero-Shot è¯„ä¼°å¯¹æ¯”è„šæœ¬ä½¿ç”¨è¯´æ˜

## ğŸ“‹ åŠŸèƒ½è¯´æ˜

è¿™ä¸ªè„šæœ¬ç”¨äºå¯¹æ¯”**åŸå§‹æ¨¡å‹**å’Œ**å‰ªæå¾®è°ƒæ¨¡å‹**åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„Zero-Shotæ€§èƒ½ã€‚

### æ”¯æŒçš„è¯„ä¼°ä»»åŠ¡

| ä»»åŠ¡ | å…¨ç§° | ç±»å‹ | è¯´æ˜ |
|------|------|------|------|
| **boolq** | BoolQ | å¸ƒå°”é—®ç­” | åˆ¤æ–­é—®é¢˜ç­”æ¡ˆæ˜¯True/False |
| **rte** | RTE | æ–‡æœ¬è•´å« | åˆ¤æ–­ä¸¤ä¸ªå¥å­æ˜¯å¦æœ‰è•´å«å…³ç³» |
| **hellaswag** | HellaSwag | å¸¸è¯†æ¨ç† | é€‰æ‹©æœ€åˆç†çš„å¥å­ç»­å†™ |
| **winogrande** | WinoGrande | ä»£è¯æ¶ˆæ­§ | åˆ¤æ–­ä»£è¯æŒ‡ä»£å¯¹è±¡ |
| **arc_easy** | ARC-Easy | ç§‘å­¦é—®ç­”(ç®€å•) | å°å­¦ç§‘å­¦é€‰æ‹©é¢˜ |
| **arc_challenge** | ARC-Challenge | ç§‘å­¦é—®ç­”(å›°éš¾) | ä¸­å­¦ç§‘å­¦é€‰æ‹©é¢˜ |
| **openbookqa** | OpenBookQA | å¼€æ”¾ä¹¦ç±é—®ç­” | åŸºäºç§‘å­¦çŸ¥è¯†çš„é—®ç­” |

### è¯„ä¼°æŒ‡æ ‡

- **WikiText2 PPL**: å›°æƒ‘åº¦ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
- **Accuracy**: å„ä»»åŠ¡çš„å‡†ç¡®ç‡ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
- **Sparsity**: æ¨¡å‹ç¨€ç–åº¦

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1: ä½¿ç”¨Shellè„šæœ¬ï¼ˆæ¨èï¼‰

```bash
cd /home/jjji/Research/Hybird-Kernel/wanda
bash run_eval_compare.sh
```

### æ–¹æ³•2: ç›´æ¥è¿è¡ŒPythonè„šæœ¬

```bash
cd /home/jjji/Research/Hybird-Kernel/wanda

python eval_zero_shot_compare.py \
    --original_model /mnt/sdb/llm_models/Llama-2-7b-hf \
    --pruned_model out/llama2_7b/block_16x16_three_tier_0.35_0.45_0.2/wanda/dense_finetuned_model \
    --tasks boolq rte hellaswag winogrande arc_easy arc_challenge openbookqa \
    --output_dir eval_results
```

---

## âš™ï¸ å‚æ•°è¯´æ˜

### å¿…éœ€å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--original_model` | åŸå§‹æ¨¡å‹è·¯å¾„ | `/mnt/sdb/llm_models/Llama-2-7b-hf` |
| `--pruned_model` | å‰ªæå¾®è°ƒæ¨¡å‹è·¯å¾„ | `out/llama2_7b/.../dense_finetuned_model` |

### å¯é€‰å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--tasks` | è¯„ä¼°ä»»åŠ¡åˆ—è¡¨ | æ‰€æœ‰7ä¸ªä»»åŠ¡ |
| `--output_dir` | ç»“æœä¿å­˜ç›®å½• | `eval_results` |
| `--nsamples` | PPLè¯„ä¼°æ ·æœ¬æ•° | 128 |
| `--seed` | éšæœºç§å­ | 0 |
| `--cache_dir` | æ¨¡å‹ç¼“å­˜ç›®å½• | `llm_weights` |

---

## ğŸ“Š è¾“å‡ºç»“æœ

### 1. ç»ˆç«¯è¾“å‡º

è„šæœ¬ä¼šåœ¨ç»ˆç«¯æ‰“å°è¯¦ç»†çš„å¯¹æ¯”è¡¨æ ¼ï¼š

```
==================================================================================================
COMPARISON RESULTS
==================================================================================================

Original Model: Original Model
  - Sparsity: 0.00%
  - WikiText2 PPL: 5.4723

Pruned Model: Pruned & Finetuned Model
  - Sparsity: 50.23%
  - WikiText2 PPL: 6.8945
  - PPL Degradation: 1.4222

Task                 Original        Pruned          Difference      Relative       
----------------------------------------------------------------------------------------------------
boolq                0.6234          0.5987          -0.0247         -3.96%
rte                  0.5812          0.5523          -0.0289         -4.97%
hellaswag            0.5789          0.5456          -0.0333         -5.75%
winogrande           0.6934          0.6712          -0.0222         -3.20%
arc_easy             0.7456          0.7234          -0.0222         -2.98%
arc_challenge        0.4523          0.4312          -0.0211         -4.66%
openbookqa           0.3456          0.3289          -0.0167         -4.83%
==================================================================================================

AVERAGE              0.5743          0.5502          -0.0241         -4.19%
==================================================================================================
```

### 2. JSONæ–‡ä»¶

ä¿å­˜åœ¨ `eval_results/comparison_YYYYMMDD_HHMMSS.json`

```json
{
  "original": {
    "model_name": "Original Model",
    "model_path": "/mnt/sdb/llm_models/Llama-2-7b-hf",
    "sparsity": 0.0,
    "wikitext_ppl": 5.4723,
    "tasks": {
      "boolq": {
        "accuracy": 0.6234,
        "full_results": {...}
      },
      ...
    }
  },
  "pruned": {...}
}
```

### 3. MarkdownæŠ¥å‘Š

ä¿å­˜åœ¨ `eval_results/comparison_YYYYMMDD_HHMMSS.md`

åŒ…å«å®Œæ•´çš„å¯¹æ¯”è¡¨æ ¼å’Œåˆ†æï¼Œæ–¹ä¾¿åˆ†äº«å’ŒæŸ¥çœ‹ã€‚

---

## ğŸ”§ è‡ªå®šä¹‰è¯„ä¼°

### åªè¯„ä¼°éƒ¨åˆ†ä»»åŠ¡

```bash
python eval_zero_shot_compare.py \
    --original_model /mnt/sdb/llm_models/Llama-2-7b-hf \
    --pruned_model out/.../dense_finetuned_model \
    --tasks boolq hellaswag winogrande
```

### è¯„ä¼°ä¸åŒçš„å‰ªææ¨¡å‹

```bash
python eval_zero_shot_compare.py \
    --original_model /mnt/sdb/llm_models/Llama-2-7b-hf \
    --pruned_model out/llama2_7b/another_pruned_model \
    --output_dir eval_results_v2
```

### ä¿®æ”¹Shellè„šæœ¬ä¸­çš„è·¯å¾„

ç¼–è¾‘ `run_eval_compare.sh`ï¼š

```bash
# ä¿®æ”¹è¿™äº›å˜é‡
ORIGINAL_MODEL="/path/to/your/original/model"
PRUNED_MODEL="path/to/your/pruned/model"
TASKS="boolq rte hellaswag"  # åªè¯„ä¼°è¿™3ä¸ªä»»åŠ¡
```

---

## â±ï¸ é¢„è®¡è¿è¡Œæ—¶é—´

| æ¨¡å‹å¤§å° | ä»»åŠ¡æ•°é‡ | é¢„è®¡æ—¶é—´ |
|---------|---------|---------|
| 7B | 7ä¸ªä»»åŠ¡ | ~30-60åˆ†é’Ÿ |
| 7B | 3ä¸ªä»»åŠ¡ | ~15-30åˆ†é’Ÿ |
| 13B | 7ä¸ªä»»åŠ¡ | ~60-120åˆ†é’Ÿ |

**æ³¨æ„**ï¼š
- é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ•°æ®é›†ï¼Œæ—¶é—´ä¼šæ›´é•¿
- ä½¿ç”¨å¤šGPUå¯ä»¥åŠ é€Ÿè¯„ä¼°
- HellaSwagæ•°æ®é›†è¾ƒå¤§ï¼Œè¯„ä¼°æ—¶é—´è¾ƒé•¿

---

## ğŸ“ æ³¨æ„äº‹é¡¹

### 1. ç¯å¢ƒè¦æ±‚

ç¡®ä¿ä½ åœ¨æ­£ç¡®çš„condaç¯å¢ƒä¸­ï¼š

```bash
# ä½¿ç”¨prune_llmç¯å¢ƒï¼ˆtransformers 4.36.0ï¼‰
conda activate prune_llm
```

### 2. æ˜¾å­˜è¦æ±‚

- **7Bæ¨¡å‹**: è‡³å°‘éœ€è¦1å¼ 24GBæ˜¾å­˜çš„GPUï¼ˆå¦‚RTX 3090/4090, A5000ï¼‰
- **13Bæ¨¡å‹**: è‡³å°‘éœ€è¦1å¼ 40GBæ˜¾å­˜çš„GPUï¼ˆå¦‚A100ï¼‰
- å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨ä½¿ç”¨`device_map="auto"`åˆ†é…åˆ°å¤šGPU

### 3. æ•°æ®é›†ä¸‹è½½

é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½è¯„ä¼°æ•°æ®é›†åˆ° `~/.cache/huggingface/datasets/`

å¦‚æœä¸‹è½½å¤±è´¥ï¼Œå¯ä»¥æ‰‹åŠ¨è®¾ç½®é•œåƒï¼š

```bash
export HF_ENDPOINT=https://hf-mirror.com
```

### 4. ç»“æœè§£è¯»

- **PPL Degradation**: å›°æƒ‘åº¦å¢åŠ ï¼Œè¡¨ç¤ºè¯­è¨€å»ºæ¨¡èƒ½åŠ›ä¸‹é™
- **Accuracy Difference**: è´Ÿå€¼è¡¨ç¤ºæ€§èƒ½ä¸‹é™ï¼Œæ­£å€¼è¡¨ç¤ºæ€§èƒ½æå‡
- **Relative**: ç›¸å¯¹å˜åŒ–ç™¾åˆ†æ¯”ï¼Œé€šå¸¸å‰ªæåä¼šæœ‰3-5%çš„æ€§èƒ½ä¸‹é™

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: æç¤ºæ‰¾ä¸åˆ°æ¨¡å‹

**A**: æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼š

```bash
ls -lh /mnt/sdb/llm_models/Llama-2-7b-hf
ls -lh out/llama2_7b/block_16x16_three_tier_0.35_0.45_0.2/wanda/dense_finetuned_model
```

### Q2: CUDA out of memory

**A**: å‡å°‘è¯„ä¼°ä»»åŠ¡æ•°é‡æˆ–ä½¿ç”¨æ›´å¤§æ˜¾å­˜çš„GPUï¼š

```bash
# åªè¯„ä¼°3ä¸ªä»»åŠ¡
python eval_zero_shot_compare.py --tasks boolq rte hellaswag
```

### Q3: è¯„ä¼°é€Ÿåº¦å¤ªæ…¢

**A**: 
1. ä½¿ç”¨æ›´å°‘çš„ä»»åŠ¡
2. å‡å°‘PPLè¯„ä¼°æ ·æœ¬æ•°ï¼š`--nsamples 64`
3. ä½¿ç”¨å¤šGPUåŠ é€Ÿ

### Q4: æ•°æ®é›†ä¸‹è½½å¤±è´¥

**A**: ä½¿ç”¨å›½å†…é•œåƒï¼š

```bash
export HF_ENDPOINT=https://hf-mirror.com
pip install -U huggingface_hub
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [Wandaè®ºæ–‡](https://arxiv.org/abs/2306.11695)
- [LM Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)

---

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹é¡¹ç›®READMEæˆ–æäº¤Issueã€‚

