# å‰ªæ vs å¾®è°ƒï¼šæ•°æ®ä½¿ç”¨çš„åŒºåˆ«

æœ¬æ–‡æ¡£è¯¦ç»†è§£é‡Šå‰ªæå’Œå¾®è°ƒæ—¶æ•°æ®ä½¿ç”¨çš„åŒºåˆ«ï¼Œä»¥åŠä¸ºä»€ä¹ˆé—®ç­”æ•°æ®é›†å¯ä»¥ç”¨äºå‰ªæä½†éœ€è¦ç‰¹æ®Šå¤„ç†ã€‚

---

## ğŸ” æ ¸å¿ƒåŒºåˆ«

### å‰ªææ—¶çš„æ•°æ®ä½¿ç”¨

**ç›®çš„**: è®¡ç®—æ¿€æ´»å€¼ï¼Œç¡®å®šæƒé‡é‡è¦æ€§

**è¿‡ç¨‹**:
```python
# 1. å‰å‘ä¼ æ’­ï¼ˆä¸è®¡ç®—æ¢¯åº¦ï¼‰
for j in range(nsamples):
    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦
        outs[j] = layer(inps[j])  # åªæ˜¯å‰å‘ä¼ æ’­

# 2. æ”¶é›†æ¿€æ´»å€¼
wrapped_layers[name].add_batch(inp[0].data, out.data)

# 3. è®¡ç®— Wanda score
W_metric = |W| * sqrt(activation_norm)

# 4. æ ¹æ® score å‰ªæ
prune_weights_with_lowest_scores()
```

**å…³é”®ç‚¹**:
- âœ… **åªéœ€è¦è¾“å…¥æ–‡æœ¬**ï¼ˆä¸éœ€è¦æ ‡ç­¾ï¼‰
- âœ… **åªåšå‰å‘ä¼ æ’­**ï¼ˆä¸æ›´æ–°æƒé‡ï¼‰
- âœ… **åªæ”¶é›†æ¿€æ´»å€¼**ï¼ˆç”¨äºè®¡ç®—é‡è¦æ€§ï¼‰
- âœ… **ä¸éœ€è¦ç†è§£ä»»åŠ¡**ï¼ˆåªéœ€è¦æ–‡æœ¬åˆ†å¸ƒï¼‰

---

### å¾®è°ƒæ—¶çš„æ•°æ®ä½¿ç”¨

**ç›®çš„**: æ›´æ–°æƒé‡ï¼Œæ¢å¤æ€§èƒ½

**è¿‡ç¨‹**:
```python
# 1. å‰å‘ä¼ æ’­ï¼ˆè®¡ç®—æ¢¯åº¦ï¼‰
outputs = model(input_ids, labels=labels)  # éœ€è¦æ ‡ç­¾

# 2. è®¡ç®—æŸå¤±
loss = outputs.loss

# 3. åå‘ä¼ æ’­
loss.backward()

# 4. æ›´æ–°æƒé‡
optimizer.step()
```

**å…³é”®ç‚¹**:
- âš ï¸ **éœ€è¦è¾“å…¥-è¾“å‡ºå¯¹**ï¼ˆéœ€è¦æ ‡ç­¾ï¼‰
- âš ï¸ **éœ€è¦è®¡ç®—æŸå¤±**ï¼ˆéœ€è¦çŸ¥é“æ­£ç¡®ç­”æ¡ˆï¼‰
- âš ï¸ **éœ€è¦æ›´æ–°æƒé‡**ï¼ˆéœ€è¦æ¢¯åº¦ï¼‰
- âš ï¸ **éœ€è¦ç†è§£ä»»åŠ¡**ï¼ˆéœ€è¦ç‰¹æ®Šæ ¼å¼ï¼‰

---

## ğŸ“Š å¯¹æ¯”è¡¨æ ¼

| ç‰¹æ€§ | å‰ªæï¼ˆPruningï¼‰ | å¾®è°ƒï¼ˆFine-tuningï¼‰ |
|------|----------------|-------------------|
| **æ•°æ®éœ€æ±‚** | åªéœ€è¦è¾“å…¥æ–‡æœ¬ | éœ€è¦è¾“å…¥-è¾“å‡ºå¯¹ |
| **æ¢¯åº¦è®¡ç®—** | âŒ ä¸éœ€è¦ | âœ… éœ€è¦ |
| **æƒé‡æ›´æ–°** | âŒ ä¸æ›´æ–° | âœ… æ›´æ–° |
| **ä»»åŠ¡ç†è§£** | âŒ ä¸éœ€è¦ | âœ… éœ€è¦ |
| **Prompt æ ¼å¼** | âŒ ä¸éœ€è¦ | âœ… éœ€è¦ |
| **æ ‡ç­¾** | âŒ ä¸éœ€è¦ | âœ… éœ€è¦ |
| **ç›®çš„** | ç¡®å®šæƒé‡é‡è¦æ€§ | æ¢å¤/æå‡æ€§èƒ½ |

---

## ğŸ¤” é—®ç­”æ•°æ®é›†ç”¨äºå‰ªæï¼šå¯è¡Œå—ï¼Ÿ

### ç­”æ¡ˆï¼šå®Œå…¨å¯è¡Œï¼

**åŸå› **:
1. âœ… å‰ªæåªéœ€è¦æ–‡æœ¬è¾“å…¥ï¼Œä¸éœ€è¦æ ‡ç­¾
2. âœ… é—®ç­”æ•°æ®é›†æœ‰ä¸°å¯Œçš„æ–‡æœ¬ï¼ˆcontext + questionï¼‰
3. âœ… ä¸éœ€è¦ç‰¹æ®Šçš„ prompt æ ¼å¼
4. âœ… åªéœ€è¦å‰å‘ä¼ æ’­ï¼Œä¸éœ€è¦ç†è§£ä»»åŠ¡

### ç¤ºä¾‹

#### WikiText2ï¼ˆå½“å‰ä½¿ç”¨ï¼‰

```python
# çº¯æ–‡æœ¬
text = "The Normans were the people who in the 10th and 11th centuries..."

# ç›´æ¥ tokenize
input_ids = tokenizer(text, return_tensors='pt')

# å‰å‘ä¼ æ’­
outputs = model(input_ids)  # æ”¶é›†æ¿€æ´»å€¼
```

#### SQuADï¼ˆé—®ç­”æ•°æ®é›†ï¼‰

```python
# é—®ç­”æ•°æ®
context = "The Normans were the people who in the 10th and 11th centuries..."
question = "In what country is Normandy located?"

# æ–¹å¼ 1: åªä½¿ç”¨ contextï¼ˆç±»ä¼¼ WikiText2ï¼‰
text = context
input_ids = tokenizer(text, return_tensors='pt')
outputs = model(input_ids)  # æ”¶é›†æ¿€æ´»å€¼

# æ–¹å¼ 2: ä½¿ç”¨ context + questionï¼ˆæ›´è´´è¿‘å®é™…ä½¿ç”¨ï¼‰
text = f"{context} {question}"
input_ids = tokenizer(text, return_tensors='pt')
outputs = model(input_ids)  # æ”¶é›†æ¿€æ´»å€¼

# æ–¹å¼ 3: ä½¿ç”¨ç®€å•çš„æ ¼å¼ï¼ˆæ¨èï¼‰
text = f"Context: {context}\nQuestion: {question}"
input_ids = tokenizer(text, return_tensors='pt')
outputs = model(input_ids)  # æ”¶é›†æ¿€æ´»å€¼
```

**å…³é”®ç‚¹**:
- âœ… ä¸éœ€è¦ç­”æ¡ˆï¼ˆanswerï¼‰
- âœ… ä¸éœ€è¦ç‰¹æ®Šçš„ prompt
- âœ… åªéœ€è¦æŠŠæ–‡æœ¬æ‹¼æ¥èµ·æ¥
- âœ… æ ¼å¼å¯ä»¥å¾ˆç®€å•

---

## ğŸ¯ "ç‰¹æ®Šçš„ Prompt" æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ

### å‰ªææ—¶ï¼šä¸éœ€è¦ç‰¹æ®Š Prompt

```python
# ç®€å•æ‹¼æ¥å³å¯
text = f"{context} {question}"

# æˆ–è€…ç¨å¾®æ ¼å¼åŒ–
text = f"Context: {context}\nQuestion: {question}"

# ç”šè‡³åªç”¨ context
text = context
```

**åŸå› **: å‰ªæåªéœ€è¦æ–‡æœ¬è¾“å…¥ï¼Œä¸éœ€è¦ç†è§£ä»»åŠ¡æ ¼å¼ã€‚

---

### å¾®è°ƒæ—¶ï¼šéœ€è¦ç‰¹æ®Š Prompt

```python
# âŒ é”™è¯¯ï¼šç®€å•æ‹¼æ¥
text = f"{context} {question} {answer}"
# é—®é¢˜ï¼šæ¨¡å‹ä¸çŸ¥é“è¿™æ˜¯ä¸€ä¸ªé—®ç­”ä»»åŠ¡

# âœ… æ­£ç¡®ï¼šä½¿ç”¨ Prompt æ¨¡æ¿
text = f"""Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
Answer the question based on the context.

### Input:
Context: {context}
Question: {question}

### Response:
{answer}"""

# æˆ–è€…ä½¿ç”¨æ›´ç®€å•çš„æ ¼å¼
text = f"Context: {context}\nQuestion: {question}\nAnswer: {answer}"
```

**åŸå› **: å¾®è°ƒéœ€è¦å‘Šè¯‰æ¨¡å‹ï¼š
1. è¿™æ˜¯ä¸€ä¸ªä»€ä¹ˆä»»åŠ¡ï¼ˆé—®ç­”ï¼‰
2. è¾“å…¥æ˜¯ä»€ä¹ˆï¼ˆcontext + questionï¼‰
3. è¾“å‡ºæ˜¯ä»€ä¹ˆï¼ˆanswerï¼‰
4. å¦‚ä½•æ ¼å¼åŒ–ï¼ˆInstruction, Input, Responseï¼‰

---

## ğŸ“‹ å®é™…ä¾‹å­å¯¹æ¯”

### ä¾‹å­ï¼šSQuAD æ•°æ®

```json
{
  "context": "The Normans were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France.",
  "question": "In what country is Normandy located?",
  "answer": "France"
}
```

### å‰ªææ—¶ä½¿ç”¨ï¼ˆç®€å•ï¼‰

```python
# lib/data.py
def get_squad(nsamples, seed, seqlen, tokenizer):
    dataset = load_dataset('squad_v2', split='train')
    
    trainloader = []
    for _ in range(nsamples):
        i = random.randint(0, len(dataset) - 1)
        sample = dataset[i]
        
        # ç®€å•æ‹¼æ¥å³å¯
        text = f"{sample['context']} {sample['question']}"
        
        # Tokenize
        inp = tokenizer(text, return_tensors='pt', max_length=seqlen, truncation=True)
        
        trainloader.append((inp.input_ids, inp.input_ids.clone()))
    
    return trainloader, testenc
```

**å…³é”®ç‚¹**:
- âœ… ä¸éœ€è¦ answer
- âœ… ä¸éœ€è¦ç‰¹æ®Šæ ¼å¼
- âœ… ç®€å•æ‹¼æ¥å³å¯

---

### å¾®è°ƒæ—¶ä½¿ç”¨ï¼ˆå¤æ‚ï¼‰

```python
# dense_ft/finetune_squad.py
def preprocess_squad(examples, tokenizer):
    inputs = []
    for context, question, answers in zip(...):
        answer_text = answers['text'][0]
        
        # éœ€è¦ç‰¹æ®Šçš„ Prompt æ ¼å¼
        text = f"""Answer the question based on the context.

Context: {context}
Question: {question}
Answer: {answer_text}"""
        
        inputs.append(text)
    
    # Tokenize
    model_inputs = tokenizer(inputs, ...)
    
    # è®¾ç½® labelsï¼ˆç”¨äºè®¡ç®—æŸå¤±ï¼‰
    model_inputs['labels'] = model_inputs['input_ids'].clone()
    
    return model_inputs
```

**å…³é”®ç‚¹**:
- âš ï¸ éœ€è¦ answerï¼ˆç”¨äºè®¡ç®—æŸå¤±ï¼‰
- âš ï¸ éœ€è¦ç‰¹æ®Šæ ¼å¼ï¼ˆå‘Šè¯‰æ¨¡å‹è¿™æ˜¯é—®ç­”ä»»åŠ¡ï¼‰
- âš ï¸ éœ€è¦è®¾ç½® labelsï¼ˆç”¨äºè®­ç»ƒï¼‰

---

## ğŸ’¡ ä¸ºä»€ä¹ˆé—®ç­”æ•°æ®é›†ç”¨äºå‰ªæ"ä¸å¤ªå¥½"ï¼Ÿ

### ä¸æ˜¯"ä¸å¤ªå¥½"ï¼Œè€Œæ˜¯"éœ€è¦æƒè¡¡"

#### âœ… ä¼˜ç‚¹

1. **æ›´è´´è¿‘å®é™…ä½¿ç”¨**
   - å¦‚æœä½ çš„ç›®æ ‡æ˜¯é—®ç­”ä»»åŠ¡
   - ä½¿ç”¨é—®ç­”æ•°æ®å‰ªæä¼šä¿ç•™æ›´å¤šç›¸å…³æƒé‡

2. **æ–‡æœ¬è´¨é‡é«˜**
   - SQuAD çš„ context éƒ½æ˜¯ç»´åŸºç™¾ç§‘æ–‡ç« 
   - è´¨é‡å’Œ WikiText2 ç±»ä¼¼

3. **æ–‡æœ¬å¤šæ ·æ€§**
   - åŒ…å«å„ç§ä¸»é¢˜çš„æ–‡ç« 
   - é—®é¢˜å½¢å¼å¤šæ ·

#### âš ï¸ ç¼ºç‚¹

1. **å¤±å»é€šç”¨æ€§**
   - å‰ªæåçš„æ¨¡å‹å¯èƒ½åœ¨å…¶ä»–ä»»åŠ¡ä¸Šæ€§èƒ½ä¸‹é™
   - ä¾‹å¦‚ï¼šç”¨ SQuAD å‰ªæï¼Œåœ¨ GSM8K ä¸Šå¯èƒ½è¡¨ç°ä¸å¥½

2. **æ–‡æœ¬åˆ†å¸ƒåå·®**
   - SQuAD ä¸»è¦æ˜¯äº‹å®æ€§é—®ç­”
   - å¯èƒ½ä¸é€‚åˆå…¶ä»–ç±»å‹çš„ä»»åŠ¡

3. **æ•°æ®é‡é™åˆ¶**
   - SQuAD è®­ç»ƒé›† ~87k æ ·æœ¬
   - WikiText2 æ˜¯è¿ç»­æ–‡æœ¬ï¼Œå¯ä»¥æ— é™é‡‡æ ·

---

## ğŸ¯ æ¨èç­–ç•¥

### ç­–ç•¥ 1: é€šç”¨å‰ªæï¼ˆæ¨èï¼‰

```bash
# ä½¿ç”¨ WikiText2 å‰ªæ
python main_block_three_tier.py \
    --model /mnt/sdb/llm_models/Llama-2-7b-hf \
    --calibration_dataset wikitext2 \
    --nsamples 128
```

**ä¼˜ç‚¹**:
- âœ… ä¿æŒé€šç”¨æ€§
- âœ… åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°ç¨³å®š

**é€‚ç”¨åœºæ™¯**:
- éœ€è¦åœ¨å¤šä¸ªä»»åŠ¡ä¸Šä½¿ç”¨
- ä¸ç¡®å®šæœ€ç»ˆç”¨é€”

---

### ç­–ç•¥ 2: ä»»åŠ¡ç‰¹å®šå‰ªæ

```bash
# ä½¿ç”¨ SQuAD å‰ªæ
python main_block_three_tier.py \
    --model /mnt/sdb/llm_models/Llama-2-7b-hf \
    --calibration_dataset squad \
    --nsamples 128
```

**ä¼˜ç‚¹**:
- âœ… åœ¨ç›®æ ‡ä»»åŠ¡ä¸Šæ€§èƒ½æ›´å¥½
- âœ… æ¿€æ´»å€¼æ›´è´´è¿‘å®é™…ä½¿ç”¨

**ç¼ºç‚¹**:
- âš ï¸ åœ¨å…¶ä»–ä»»åŠ¡ä¸Šå¯èƒ½æ€§èƒ½ä¸‹é™

**é€‚ç”¨åœºæ™¯**:
- åªå…³å¿ƒç‰¹å®šä»»åŠ¡
- è¿½æ±‚æè‡´æ€§èƒ½

---

### ç­–ç•¥ 3: æ··åˆå‰ªæ

```bash
# ä½¿ç”¨ WikiText2 + SQuAD æ··åˆå‰ªæ
# éœ€è¦ä¿®æ”¹ä»£ç æ”¯æŒæ··åˆæ•°æ®é›†
```

**ä¼˜ç‚¹**:
- âœ… å¹³è¡¡é€šç”¨æ€§å’Œä»»åŠ¡æ€§èƒ½

---

## ğŸ“Š å®éªŒå»ºè®®

### å¯¹æ¯”å®éªŒ

| å®éªŒ | å‰ªææ•°æ® | å¾®è°ƒæ•°æ® | è¯„ä¼°ä»»åŠ¡ |
|------|---------|---------|---------|
| **Exp 1** | WikiText2 | WikiText2 | SQuAD, GSM8K, BoolQ |
| **Exp 2** | SQuAD | SQuAD | SQuAD, GSM8K, BoolQ |
| **Exp 3** | WikiText2 | SQuAD | SQuAD, GSM8K, BoolQ |

**é¢„æœŸç»“æœ**:
- Exp 1: é€šç”¨æ€§èƒ½æœ€å¥½
- Exp 2: SQuAD æ€§èƒ½æœ€å¥½ï¼Œä½†å…¶ä»–ä»»åŠ¡ä¸‹é™
- Exp 3: å¹³è¡¡æ–¹æ¡ˆï¼ŒSQuAD æ€§èƒ½å¥½ï¼Œé€šç”¨æ€§ä¿æŒ

---

## âœ… æ€»ç»“

### Q1: é—®ç­”æ•°æ®é›†ç”¨äºå‰ªæå¯è¡Œå—ï¼Ÿ

**A: å®Œå…¨å¯è¡Œï¼**

- âœ… å‰ªæåªéœ€è¦æ–‡æœ¬è¾“å…¥ï¼Œä¸éœ€è¦æ ‡ç­¾
- âœ… ä¸éœ€è¦ç‰¹æ®Šçš„ prompt æ ¼å¼
- âœ… ç®€å•æ‹¼æ¥ context + question å³å¯

### Q2: ä¸ºä»€ä¹ˆè¯´"ä¸å¤ªå¥½"ï¼Ÿ

**A: ä¸æ˜¯"ä¸å¤ªå¥½"ï¼Œè€Œæ˜¯"éœ€è¦æƒè¡¡"**

- âœ… å¦‚æœåªå…³å¿ƒç‰¹å®šä»»åŠ¡ï¼Œç”¨ä»»åŠ¡æ•°æ®å‰ªææ›´å¥½
- âš ï¸ å¦‚æœéœ€è¦é€šç”¨æ€§ï¼Œç”¨ WikiText2 å‰ªææ›´å¥½
- ğŸ’¡ æ¨èï¼šWikiText2 å‰ªæ + ä»»åŠ¡æ•°æ®å¾®è°ƒ

### Q3: "ç‰¹æ®Šçš„ Prompt" æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ

**A: åªåœ¨å¾®è°ƒæ—¶éœ€è¦ï¼Œå‰ªææ—¶ä¸éœ€è¦**

- **å‰ªæ**: ç®€å•æ‹¼æ¥æ–‡æœ¬å³å¯
- **å¾®è°ƒ**: éœ€è¦ Prompt æ¨¡æ¿å‘Šè¯‰æ¨¡å‹ä»»åŠ¡æ ¼å¼

---

## ğŸ”§ å®ç°å»ºè®®

### å‰ªææ—¶

```python
# ç®€å•å³å¯
text = f"{context} {question}"
```

### å¾®è°ƒæ—¶

```python
# éœ€è¦æ ¼å¼åŒ–
text = f"""Context: {context}
Question: {question}
Answer: {answer}"""
```

---

**æœ€åæ›´æ–°**: 2025-01-XX  
**ç»´æŠ¤è€…**: Jiajun Ji  
**é¡¹ç›®**: Wanda Hybrid Pruning

